# -*- coding: utf-8 -*-
"""network_compression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WpRMbUdcgHe-Jp0glJAOGTfhXcNM99dc
"""

!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip
!unzip -q food-11.zip
!mv food-11 data
!ls data

!gdown --id '1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN' --output teacher_resnet18.bin

"""CNN Architecture Design"""

import torch.nn as nn
import torch.nn.functional as F
import torch

class StudentNet(nn.Module):
  '''
  在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。
  你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。
  另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。
  '''
  def __init__(self, base=16, width_mult=1):
    '''
      Args:
        base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。
        width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        
    '''
    super(StudentNet, self).__init__()
    multiplier = [1, 2, 4, 8, 16, 16, 16, 16]
    bandwidth = [ base * m for m in multiplier]#bandwidth: 每一層Layer所使用的channel數量

    # 我們只Pruning第三層以後的Layer
    for i in range(3, 7):bandwidth[i] = int(bandwidth[i] * width_mult)

    self.cnn = nn.Sequential(
      #Conv2d input output kernel_size stride padding group  
      nn.Sequential(nn.Conv2d(3, bandwidth[0], 3, 1, 1),nn.BatchNorm2d(bandwidth[0]),nn.ReLU6(),nn.MaxPool2d(2, 2, 0),),#第一层Convolution Layer
      # 接下來每一個Sequential Block都一樣，所以我們只講一個Block
      nn.Sequential(
        nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),#Depthwise  Depthwise卷积后再加ReLU效果变差
        nn.BatchNorm2d(bandwidth[0]),
        nn.ReLU6(),#使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。
        nn.Conv2d(bandwidth[0], bandwidth[1], 1),# Pointwise 經驗上Pointwise + ReLU效果都會變差。
        nn.MaxPool2d(2, 2, 0),
      ),
      nn.Sequential(
        nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),#Depthwise
        nn.BatchNorm2d(bandwidth[1]),
        nn.ReLU6(),
        nn.Conv2d(bandwidth[1], bandwidth[2], 1),#Pointwise
        nn.MaxPool2d(2, 2, 0),
      ),
      nn.Sequential(
        nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),#Depthwise
        nn.BatchNorm2d(bandwidth[2]),
        nn.ReLU6(),
        nn.Conv2d(bandwidth[2], bandwidth[3], 1),#Pointwise
        nn.MaxPool2d(2, 2, 0),
      ),
      nn.Sequential(
        nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),
        nn.BatchNorm2d(bandwidth[3]),
        nn.ReLU6(),
        nn.Conv2d(bandwidth[3], bandwidth[4], 1),
      ),
      nn.Sequential(
        nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),
        nn.BatchNorm2d(bandwidth[4]),
        nn.ReLU6(),
        nn.Conv2d(bandwidth[4], bandwidth[5], 1),
      ),
      nn.Sequential(
        nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),
        nn.BatchNorm2d(bandwidth[5]),
        nn.ReLU6(),
        nn.Conv2d(bandwidth[5], bandwidth[6], 1),
      ),
      nn.Sequential(
        nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),
        nn.BatchNorm2d(bandwidth[6]),
        nn.ReLU6(),
        nn.Conv2d(bandwidth[6], bandwidth[7], 1),
      ),
      nn.AdaptiveAvgPool2d((1, 1)),#池化成 1*1的图片
    )
    self.fc = nn.Sequential(nn.Linear(bandwidth[7], 11),)

  def forward(self, x):
    out = self.cnn(x)
    out = out.view(out.size()[0], -1)
    return self.fc(out)

import re
import torch
import numpy as np

from glob import glob
from PIL import Image
import torchvision.transforms as transforms

trainTransform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),#镜像填充
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
])

testTransform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.CenterCrop(256),
    transforms.ToTensor(),
])

class MyDataset(torch.utils.data.Dataset):
  def __init__(self, folderName, transform=None):
    self.transform = transform
    self.data = []
    self.label = []

    for img_path in sorted(glob(folderName + '/*.jpg')):
      class_idx = int(re.findall(re.compile(r'\d+'), img_path)[0])
      image = Image.open(img_path).resize((128, 128))
      image = np.array(image)
      self.data.append(image)
      self.label.append(class_idx)

  def __len__(self):
    return len(self.data)

  def __getitem__(self, idx):
    image = self.transform(self.data[idx])
    return image, self.label[idx]

def get_dataloader(mode='training', batch_size=32):
  dataset = MyDataset(f'./data/{mode}',transform=trainTransform if mode == 'training' else testTransform)
  dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True)
  return dataloader

train_dataloader = get_dataloader('training', batch_size=32)
valid_dataloader = get_dataloader('validation', batch_size=32)

import torchvision.models as models
import torch.optim as optim
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

teacher_net = models.resnet18(pretrained=False, num_classes=11).to(device)
student_net = StudentNet(base=16).to(device)

teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))
optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)

"""* $Loss = \alpha T^2 \times KL(\frac{\text{Teacher's Logits}}{T} || \frac{\text{Student's Logits}}{T}) + (1-\alpha)(\text{Original Loss})$"""

def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):
    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)#  
    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。
    soft_loss = (alpha * T * T) * nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),F.softmax(teacher_outputs/T, dim=1))
    return hard_loss + soft_loss

def run_epoch(dataloader, update=True, alpha=0.5):
  total_num, total_hit, total_loss = 0, 0, 0
  for now_step, batch_data in enumerate(dataloader):
    optimizer.zero_grad()
    inputs, hard_labels = batch_data

    inputs = inputs.cuda()#[32 3 256 256]
    hard_labels = torch.LongTensor(hard_labels).cuda()#[32]

    with torch.no_grad():
      soft_labels = teacher_net(inputs)#[32 11]告訴torch不要暫存中間值(去做backprop)以浪費記憶體空間。
    if update:
      logits = student_net(inputs)#[32 11]
      loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)
      loss.backward()
      optimizer.step()    
    else:
      with torch.no_grad():
        logits = student_net(inputs)
        loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)
        
    total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()
    total_num += len(inputs)

    total_loss += loss.item() * len(inputs)
  return total_loss / total_num, total_hit / total_num

teacher_net.eval()
for epoch in range(10):
  student_net.train()
  train_loss, train_acc = run_epoch(train_dataloader, update=True)
  student_net.eval()
  print(f'epoch {epoch:>3d}: train acc {train_acc:6.4f} valid acc {valid_acc:6.4f}')

from google.colab import drive

drive.mount('/content/drive', force_remount=True)

torch.save(student_net.state_dict(), '/content/drive/MyDrive/app/student_model.bin')

!gdown --id '12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL' --output student_custom_small.bin

"""Neuron Pruning"""

import torch.optim as optim
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

net = StudentNet()
net.load_state_dict(torch.load('student_custom_small.bin',map_location="cpu"))

criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(net.parameters(), lr=1e-3)

def run_epoch(dataloader, update=True, alpha=0.5):
  total_num, total_hit, total_loss = 0, 0, 0
  for now_step, batch_data in enumerate(dataloader):
    optimizer.zero_grad()
    inputs, labels = batch_data
    inputs = inputs.cuda()
    labels = labels.cuda()
    logits = net(inputs)
    loss = criterion(logits, labels)
    if update:
      loss.backward()
      optimizer.step()

    total_hit += torch.sum(torch.argmax(logits, dim=1) == labels).item()
    total_num += len(inputs)
    total_loss += loss.item() * len(inputs)
  return total_loss / total_num, total_hit / total_num

def network_slimming(old_model, new_model):
    params = old_model.state_dict()
    new_params = new_model.state_dict()
    selected_idx = []
    for i in range(8):
        conv_num = f'cnn.{i}.1.weight'
        importance = params[conv_num]#BatchNorm2d
        old_dim = len(importance)
        new_dim = len(new_params[conv_num])
        #16 16 32 84 128 256 256 256
        #16 16 32 64 121 243 243 243
        ranking = torch.argsort(importance, descending=True)#对第一维度进行排序
        selected_idx.append(ranking[:new_dim])#BatchNorm2d层

    now_processed = 1
    for name,param in params.items():
        if name.startswith('cnn') and param.size() != torch.Size([]) and now_processed != len(selected_idx):
            if name.startswith(f'cnn.{now_processed}.3'):now_processed=now_processed+ 1#Pointwise的weight 该层处理结束
            if name.endswith('3.weight'):
                if len(selected_idx) == now_processed:
                    new_params[name] = param[:, selected_idx[now_processed - 1]]#7.3weight 原层输出 但是改变顺序
                else:#pointwise
                    #下一层的顺序 上一层的参数
                    new_params[name] = param[selected_idx[now_processed]][:, selected_idx[now_processed - 1]]
            else:
                new_params[name] = param[selected_idx[now_processed]]#排序后 n.0  conv deepwise n.1 batchnorm n.3 bias
        else:
            new_params[name] = param #n.1 BatchNorm2d的num_batches_tracked 7.3 bias

    new_model.load_state_dict(new_params)
    return new_model

now_width_mult = 1
for i in range(5):
  now_width_mult=now_width_mult*0.95
  new_net = StudentNet(width_mult=now_width_mult).to(device)
  params = net.state_dict()
  net = network_slimming(net, new_net)

  now_best_acc = 0
  continue
  for epoch in range(5):
    net.train()
    train_loss, train_acc = run_epoch(train_dataloader, update=True)
    net.eval()
    valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)
    # 在每個width_mult的情況下，存下最好的model。
    if valid_acc > now_best_acc:
      now_best_acc = valid_acc
      torch.save(net.state_dict(), f'custom_small_rate_{now_width_mult}.bin')
    print('rate {:6.4f} epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(now_width_mult,epoch, train_loss, train_acc, valid_loss, valid_acc))

"""Weight Quantization"""

params = torch.load('student_custom_small.bin')
def encode8(params, fname):
  custom_dict = {}
  for (name, param) in params.items():
    param = np.float64(param.cpu().numpy())
    if type(param) == np.ndarray:
      min_val = np.min(param)
      max_val = np.max(param)
      param = np.round((param - min_val) / (max_val - min_val) * 255)
      param = np.uint8(param)
      custom_dict[name] = (min_val, max_val, param)
    else:
      custom_dict[name] = param
  pickle.dump(custom_dict, open(fname, 'wb'))

encode8(params, '8_bit_model.pkl')