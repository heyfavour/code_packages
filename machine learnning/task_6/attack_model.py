# -*- coding: utf-8 -*-
"""attack_model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Z0P7OybAXEPr2Xq3_T9e7L1wldUAuJO
"""

!gdown --id '14CqX3OfY9aUbhGp4OpdSHLvq2321fUB7' --output data.zip
!unzip -q -u data.zip
!ls

import os
import pandas as pd
from PIL import Image
import numpy as np

import torch
import torchvision.datasets as datasets
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as transforms
import matplotlib.pyplot as plt

device = torch.device("cuda")

# 實作一個繼承 torch.utils.data.Dataset 的 Class 來讀取圖片
class Adverdataset(Dataset):
  def __init__(self, image_path, label, transforms):
    self.image_path = image_path
    self.label = torch.from_numpy(label).long()
    self.transforms = transforms
    self.fnames = [f"{i:03d}"for i in range(200)]
    print(self.fnames)
    print(self.label)

  def __getitem__(self, idx):
    img = Image.open(os.path.join(self.image_path, self.fnames[idx] + '.png'))
    img = self.transforms(img)
    label = self.label[idx]
    return img, label
  
  def __len__(self):
    return len(self.fnames)
mean = [0.485,0.456,0.406]
std = [0.229, 0.224, 0.225]
normalize = transforms.Normalize(mean, std, inplace=False)
transform=transforms.Compose([transforms.Resize((224, 224), interpolation=3),transforms.ToTensor(),normalize])#ToTensor 归一化 Normalize标准化
labels = pd.read_csv("./data/labels.csv").loc[:, 'TrueLabel'].to_numpy()
attack_dataset = Adverdataset('./data/images', labels, transform)
data_loader = torch.utils.data.DataLoader(attack_dataset,batch_size = 1,shuffle = False)#200张图片 编号000-199 及对应编号

import torchvision.models as models
import torch.nn.functional as F

class Attacker(object):
  def __init__(self,data_loader):
    self.model = models.vgg16(pretrained = True)
    self.model.cuda()
    self.model.eval()
    self.data_loader = data_loader

  # FGSM 攻擊
  def fgsm_attack(self, image, epsilon, data_grad):
    # 找出 gradient 的方向
    sign_data_grad = data_grad.sign()#梯度转换成 1 -1
    attack_image = image + epsilon * sign_data_grad#image + gradient方向* epsilon (noise)
    return attack_image
  
  def attack(self, epsilon):
    adv_examples = []
    wrong, fail, success = 0, 0, 0
    for (train_x, train_y) in self.data_loader:
      train_x, train_y = train_x.to(device), train_y.to(device)
      train_x_origin = train_x
      train_x.requires_grad = True

      output = self.model(train_x)#[1,1000]
      predict_y = output.max(1)[1]#预测的种类 lass
      if predict_y.item()!=train_y.item():
        wrong=wrong+1
        continue
      loss = F.nll_loss(output, train_y)#预测正确的数据进行攻击
      self.model.zero_grad()
      loss.backward()
      #ATTACK
      attack_image = self.fgsm_attack(train_x, epsilon, train_x.grad.data)       
      output = self.model(attack_image)
      attack_y = output.max(1)[1]
    
      if attack_y.item() == train_y.item():
        fail = fail + 1
      else:
        success = success + 1
        adv_ex = attack_image*torch.tensor(std,device=device).view(3, 1, 1)+torch.tensor(mean,device=device).view(3, 1, 1)
        adv_ex = adv_ex.squeeze().detach().cpu().numpy() 
        origin_ex = train_x_origin*torch.tensor(std,device=device).view(3, 1, 1)+torch.tensor(mean,device = device).view(3, 1, 1)
        origin_ex = origin_ex.squeeze().detach().cpu().numpy()
        adv_examples.append((predict_y.item(), attack_y.item(), origin_ex , adv_ex))     
    final_acc = (success/(fail+success))
    print(f"Epsilon: {epsilon}  Attack Success = {final_acc}")
    return adv_examples
attacker = Attacker(data_loader)
epsilons = [0.01,0.1,0.5,1,10]#0.5开始图片已经相当模糊 取0.1即可
examples = []
for eps in epsilons:
  ex = attacker.attack(eps)
  examples.append(ex)

label_name = pd.read_csv("./data/categories.csv").loc[:, 'CategoryName'].to_numpy()
count = 0
plt.figure(figsize=(30, 30))
for i in range(len(epsilons)):
  for j in range(5):
    count = count+1
    plt.subplot(len(epsilons),5 * 2,count)
    plt.xticks([], [])
    plt.yticks([], [])
    if j == 0:plt.ylabel("Eps: {}".format(epsilons[i]), fontsize=14)
    orig,adv,orig_img, attack_img = examples[i][j]
    plt.title("original: {}".format(label_name[orig].split(',')[0]))
    orig_img = np.transpose(orig_img, (1, 2, 0))
    plt.imshow(orig_img)
    count = count +  1
    plt.subplot(len(epsilons),5 * 2,count)
    plt.title("adversarial: {}".format(label_name[adv].split(',')[0]))
    attack_img = np.transpose(attack_img, (1, 2, 0))
    plt.imshow(attack_img)
plt.tight_layout()
plt.show()